{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filter/anaconda3/envs/ptf/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from math import sqrt\n",
    "from pathlib import Path\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import dateparser\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from cleantext import clean\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import swifter\n",
    "from somajo import Tokenizer, SentenceSplitter\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from german_lemmatizer import lemmatize\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/mnt/data2/ptf/cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(texts):\n",
    "    tokenizer = Tokenizer(split_camel_case=True, token_classes=False, extra_info=False)\n",
    "    sentence_splitter = SentenceSplitter(is_tuple=False)\n",
    "    \n",
    "    results = []\n",
    "    for text in texts:\n",
    "        text = clean(text, lang='de', lower=False)\n",
    "        tokens = tokenizer.tokenize_paragraph(text)\n",
    "        sentences = sentence_splitter.split(tokens)\n",
    "        cleaned = [' '.join(s) for s in sentences]\n",
    "        results.append(cleaned)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fl(a):\n",
    "    for x in a:\n",
    "        for xx in x:\n",
    "            for xxx in xx:\n",
    "                yield xxx\n",
    "\n",
    "def flatten_array(a):\n",
    "    return list(_fl(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = Parallel(n_jobs=4, backend='multiprocessing')(delayed(get_sents)(row) for row in tqdm(list(chunks(df['text'].values, 10000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = flatten_array(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sents, open( \"s.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = pickle.load( open( \"s.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wer darf Atommacht sein , wer nicht .',\n",
       " 'Da treffen sich Regierungen , Atommächte und Anwärter auf die Bombe .',\n",
       " 'Über was wird da verhandelt ?',\n",
       " 'Die Bombe selbst steht nicht zur Disposition , für die Atommächte , sondern der Verfügungsanspruch eines Anwärters .',\n",
       " 'Der Besitz dieser Bombe verändert die politischen Optionen eines Staates , und damit auch die militärischen , in der Folge die politischen Optionen der existierenden Atommächte .',\n",
       " 'Bereits der Wille zur Bombe wird deshalb von den realen Atommächten beaufsichtigt .',\n",
       " 'Diese Mächte verhalten sich zum Willen eines ausländischen Souveräns wie Polizei .',\n",
       " 'Wer nicht gehorcht wird bestraft .',\n",
       " 'Das können diese Mächte , weil diese in der Lage sind ihre Ansprüche an das Wohlverhalten anderer Regierungen wirtschaftlich und militärisch zu erzwingen .',\n",
       " 'Von wegen hier ginge es um den Schutz vor einer militärischen Bedrohung .']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/273 [09:41<1:48:33, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed, next try! Command '--line' in image 'filter/german-lemmatizer:0.4.0' returned non-zero exit status 139: b''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 103/273 [1:03:15<1:24:40, 29.89s/it]"
     ]
    }
   ],
   "source": [
    "slem_txt = list(lemmatize(sents, n_jobs=3, chunk_size=100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( slem_txt, open( \"s_l.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = lambda x: clean(x, no_urls=True, no_digits=True, no_punct=True, no_line_breaks=True, lang='de') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slem_txt = pickle.load( open( \"lemma.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open( \"results_lemma.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/mnt/data2/ptf/zo2.txt', 'w') as outfile:\n",
    "    for r in results:\n",
    "        for d in r:\n",
    "            outfile.write('\\n'.join([ x for x in d]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( results, open( \"results_lemma.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(slem_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fucked up, need to either remove new lines or escape them for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results[:100]:\n",
    "    for d in r:\n",
    "        print(\"\\n\".join(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "á a ab aber ach acht achte achten achter achtes ag alle allein allem allen\n",
    "aller allerdings alles allgemeinen als also am an andere anderen anderem andern\n",
    "anders auch auf aus ausser außer ausserdem außerdem\n",
    "bald bei beide beiden beim beispiel bekannt bereits besonders besser besten bin\n",
    "bis bisher bist\n",
    "da dabei dadurch dafür dagegen daher dahin dahinter damals damit danach daneben\n",
    "dank dann daran darauf daraus darf darfst darin darüber darum darunter das\n",
    "dasein daselbst dass daß dasselbe davon davor dazu dazwischen dein deine deinem\n",
    "deiner dem dementsprechend demgegenüber demgemäss demgemäß demselben demzufolge\n",
    "den denen denn denselben der deren derjenige derjenigen dermassen dermaßen\n",
    "derselbe derselben des deshalb desselben dessen deswegen dich die diejenige\n",
    "diejenigen dies diese dieselbe dieselben diesem diesen dieser dieses dir doch\n",
    "dort drei drin dritte dritten dritter drittes du durch durchaus dürfen dürft\n",
    "durfte durften\n",
    "eben ebenso ehrlich eigen eigene eigenen eigener eigenes ein einander eine\n",
    "einem einen einer eines einigeeinigen einiger einiges einmal einmaleins elf en\n",
    "ende endlich entweder er erst erste ersten erster erstes es etwa etwas euch\n",
    "früher fünf fünfte fünften fünfter fünftes für\n",
    "gab ganz ganze ganzen ganzer ganzes gar gedurft gegen gegenüber gehabt gehen\n",
    "geht gekannt gekonnt gemacht gemocht gemusst genug gerade gern gesagt geschweige\n",
    "gewesen gewollt geworden gibt ging gleich gott gross groß grosse große grossen\n",
    "großen grosser großer grosses großes gut gute guter gutes\n",
    "habe haben habt hast hat hatte hätte hatten hätten heisst heißt her heute hier\n",
    "hin hinter hoch\n",
    "ich ihm ihn ihnen ihr ihre ihrem ihren ihrer ihres im immer in indem\n",
    "infolgedessen ins irgend ist\n",
    "ja jahr jahre jahren je jede jedem jeden jeder jedermann jedermanns jedoch\n",
    "jemand jemandem jemanden jene jenem jenen jener jenes jetzt\n",
    "kam kann kannst kaum kein keine keinem keinen keiner kleine kleinen kleiner\n",
    "kleines kommen kommt können könnt konnte könnte konnten kurz\n",
    "lang lange leicht leider lieber los\n",
    "machen macht machte mag magst man manche manchem manchen mancher manches mehr\n",
    "mein meine meinem meinen meiner meines mensch menschen mich mir mit mittel\n",
    "mochte möchte mochten mögen möglich mögt morgen muss muß müssen musst müsst\n",
    "musste mussten\n",
    "na nach nachdem nahm natürlich neben nein neue neuen neun neunte neunten neunter\n",
    "neuntes nicht nichts nie niemand niemandem niemanden noch nun nur\n",
    "ob oben oder offen oft ohne\n",
    "recht rechte rechten rechter rechtes richtig rund\n",
    "sagt sagte sah satt schlecht schon sechs sechste sechsten sechster sechstes\n",
    "sehr sei seid seien sein seine seinem seinen seiner seines seit seitdem selbst\n",
    "selbst sich sie sieben siebente siebenten siebenter siebentes siebte siebten\n",
    "siebter siebtes sind so solang solche solchem solchen solcher solches soll\n",
    "sollen sollte sollten sondern sonst sowie später statt\n",
    "tag tage tagen tat teil tel trotzdem tun\n",
    "über überhaupt übrigens uhr um und uns unser unsere unserer unter\n",
    "vergangene vergangenen viel viele vielem vielen vielleicht vier vierte vierten\n",
    "vierter viertes vom von vor\n",
    "wahr während währenddem währenddessen wann war wäre waren wart warum was wegen\n",
    "weil weit weiter weitere weiteren weiteres welche welchem welchen welcher\n",
    "welches wem wen wenig wenige weniger weniges wenigstens wenn wer werde werden\n",
    "werdet wessen wie wieder will willst wir wird wirklich wirst wo wohl wollen\n",
    "wollt wollte wollten worden wurde würde wurden würden\n",
    "zehn zehnte zehnten zehnter zehntes zeit zu zuerst zugleich zum zunächst zur\n",
    "zurück zusammen zwanzig zwar zwei zweite zweiten zweiter zweites zwischen\n",
    "\"\"\".split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_txt(data, name):\n",
    "    text = '\\n'.join(data)\n",
    "    print(len(text))\n",
    "    Path('/mnt/data2/ptf/co_exp/' + name + '.txt').write_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = pickle.load( open( \"s.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl(x):\n",
    "    return clean(x, no_urls=True, no_digits=True, no_punct=True, no_line_breaks=True, lang='de') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1418762/27200369 [01:29<28:18, 15174.59it/s]"
     ]
    }
   ],
   "source": [
    "sents = Parallel(n_jobs=4, backend='multiprocessing')(delayed(cl)(row) for row in tqdm(sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( sents, open( \"s_cleaned.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27200369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_txt(sents, 'orig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

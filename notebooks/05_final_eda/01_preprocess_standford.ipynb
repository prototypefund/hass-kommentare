{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting somajo\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/38/570731585cd5366da66c44f44a40d80d123399ea5a4f5f3085d46ca59b93/SoMaJo-1.10.3.tar.gz (77kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 1.5MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting regex>=2019.02.18 (from somajo)\n",
      "  Using cached https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz\n",
      "Building wheels for collected packages: somajo, regex\n",
      "  Building wheel for somajo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for somajo: filename=SoMaJo-1.10.3-cp37-none-any.whl size=78265 sha256=691d100218ba4512a8287fc085aff5372d3053c1e6c483162596e7c8b0d4b090\n",
      "  Stored in directory: /home/filter/.cache/pip/wheels/50/58/d8/a18ca802e6676dc202bc05988712ce4c4878d6e06533e76dfc\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for regex: filename=regex-2019.6.8-cp37-cp37m-linux_x86_64.whl size=610596 sha256=23bfeffe045360210acdb82b5a0c64945e99a88fbe8a35ec45f6eed8ce78d78f\n",
      "  Stored in directory: /home/filter/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
      "Successfully built somajo regex\n",
      "Installing collected packages: regex, somajo\n",
      "Successfully installed regex-2019.6.8 somajo-1.10.3\n"
     ]
    }
   ],
   "source": [
    "! pip install somajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# import dateparser\n",
    "import pandas as pd\n",
    "from cleantext import clean\n",
    "# from german_lemmatizer import lemmatize\n",
    "from joblib import Parallel, delayed\n",
    "from somajo import SentenceSplitter, Tokenizer\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp\n",
    "# stanfordnlp.download('de')   # This downloads the English models for the neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/mnt/data/stanfordnlp_resources/de_gsd_models/de_gsd_tokenizer.pt', 'pretokenized': True, 'batch_size': 1000, 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/mnt/data/stanfordnlp_resources/de_gsd_models/de_gsd_lemmatizer.pt', 'batch_size': 1000, 'lang': 'de', 'shorthand': 'de_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(pos_batch_size=bs * 10, mwt_batch_size=bs,tokenize_pretokenized=True,tokenize_batch_size=bs, lemma_batch_size=bs, models_dir='/mnt/data/stanfordnlp_resources', lang='de', processors='tokenize,lemma') # This sets up a default neural pipeline in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "á a ab aber ach acht achte achten achter achtes ag alle allein allem allen\n",
    "aller allerdings alles allgemeinen als also am an andere anderen anderem andern\n",
    "anders auch auf aus ausser außer ausserdem außerdem\n",
    "bald bei beide beiden beim beispiel bekannt bereits besonders besser besten bin\n",
    "bis bisher bist\n",
    "da dabei dadurch dafür dagegen daher dahin dahinter damals damit danach daneben\n",
    "dank dann daran darauf daraus darf darfst darin darüber darum darunter das\n",
    "dasein daselbst dass daß dasselbe davon davor dazu dazwischen dein deine deinem\n",
    "deiner dem dementsprechend demgegenüber demgemäss demgemäß demselben demzufolge\n",
    "den denen denn denselben der deren derjenige derjenigen dermassen dermaßen\n",
    "derselbe derselben des deshalb desselben dessen deswegen dich die diejenige\n",
    "diejenigen dies diese dieselbe dieselben diesem diesen dieser dieses dir doch\n",
    "dort drei drin dritte dritten dritter drittes du durch durchaus dürfen dürft\n",
    "durfte durften\n",
    "eben ebenso ehrlich eigen eigene eigenen eigener eigenes ein einander eine\n",
    "einem einen einer eines einigeeinigen einiger einiges einmal einmaleins elf en\n",
    "ende endlich entweder er erst erste ersten erster erstes es etwa etwas euch\n",
    "früher fünf fünfte fünften fünfter fünftes für\n",
    "gab ganz ganze ganzen ganzer ganzes gar gedurft gegen gegenüber gehabt gehen\n",
    "geht gekannt gekonnt gemacht gemocht gemusst genug gerade gern gesagt geschweige\n",
    "gewesen gewollt geworden gibt ging gleich gott gross groß grosse große grossen\n",
    "großen grosser großer grosses großes gut gute guter gutes\n",
    "habe haben habt hast hat hatte hätte hatten hätten heisst heißt her heute hier\n",
    "hin hinter hoch\n",
    "ich ihm ihn ihnen ihr ihre ihrem ihren ihrer ihres im immer in indem\n",
    "infolgedessen ins irgend ist\n",
    "ja jahr jahre jahren je jede jedem jeden jeder jedermann jedermanns jedoch\n",
    "jemand jemandem jemanden jene jenem jenen jener jenes jetzt\n",
    "kam kann kannst kaum kein keine keinem keinen keiner kleine kleinen kleiner\n",
    "kleines kommen kommt können könnt konnte könnte konnten kurz\n",
    "lang lange leicht leider lieber los\n",
    "machen macht machte mag magst man manche manchem manchen mancher manches mehr\n",
    "mein meine meinem meinen meiner meines mensch menschen mich mir mit mittel\n",
    "mochte möchte mochten mögen möglich mögt morgen muss muß müssen musst müsst\n",
    "musste mussten\n",
    "na nach nachdem nahm natürlich neben nein neue neuen neun neunte neunten neunter\n",
    "neuntes nicht nichts nie niemand niemandem niemanden noch nun nur\n",
    "ob oben oder offen oft ohne\n",
    "recht rechte rechten rechter rechtes richtig rund\n",
    "sagt sagte sah satt schlecht schon sechs sechste sechsten sechster sechstes\n",
    "sehr sei seid seien sein seine seinem seinen seiner seines seit seitdem selbst\n",
    "selbst sich sie sieben siebente siebenten siebenter siebentes siebte siebten\n",
    "siebter siebtes sind so solang solche solchem solchen solcher solches soll\n",
    "sollen sollte sollten sondern sonst sowie später statt\n",
    "tag tage tagen tat teil tel trotzdem tun\n",
    "über überhaupt übrigens uhr um und uns unser unsere unserer unter\n",
    "vergangene vergangenen viel viele vielem vielen vielleicht vier vierte vierten\n",
    "vierter viertes vom von vor\n",
    "wahr während währenddem währenddessen wann war wäre waren wart warum was wegen\n",
    "weil weit weiter weitere weiteren weiteres welche welchem welchen welcher\n",
    "welches wem wen wenig wenige weniger weniges wenigstens wenn wer werde werden\n",
    "werdet wessen wie wieder will willst wir wird wirklich wirst wo wohl wollen\n",
    "wollt wollte wollten worden wurde würde wurden würden\n",
    "zehn zehnte zehnten zehnter zehntes zeit zu zuerst zugleich zum zunächst zur\n",
    "zurück zusammen zwanzig zwar zwei zweite zweiten zweiter zweites zwischen\n",
    "\"\"\".split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "\n",
    "    \"\"\"\n",
    "    Yield successive n-sized chunks from l.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i : i + n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('parsed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(c):\n",
    "    final_text = ''\n",
    "    tokenizer = Tokenizer(split_camel_case=True, token_classes=False, extra_info=False)\n",
    "    sentence_splitter = SentenceSplitter(is_tuple=False)\n",
    "    for text in c:\n",
    "        text = clean(text, lang='de', lower=False)\n",
    "        tokens = tokenizer.tokenize_paragraph(text)\n",
    "        final_text += ' '.join(tokens) + '\\n'\n",
    "    print('cleaned')\n",
    "    results = [] \n",
    "    for s in tqdm(nlp(final_text).sentences):\n",
    "        results.append(' '.join([t.lemma for t in s.words if not t.lemma is None and t.lemma.lower() not in STOP_WORDS]))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3076.9334 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/3076.9334 [00:00<17:39,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 6/3076.9334 [06:55<21:28:13, 25.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 7/3076.9334 [07:15<20:03:03, 23.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 8/3076.9334 [07:20<15:22:19, 18.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 9/3076.9334 [08:07<22:44:16, 26.68s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a6861b19c9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hy_stan/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "se = Parallel(n_jobs=3)(delayed(run)(i) for i in tqdm(chunks(df['text'].values[:100000], 5000), total=df.shape[0] / 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3533"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3328199it [00:38, 86966.48it/s]\n",
      "3096it [00:00, 72439.03it/s]\n",
      "1344582it [00:37, 35984.74it/s]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for f in Path(\"/mnt/data2/ptf/final_zo\").glob(\"*.json\"):\n",
    "    with open(f) as inp:\n",
    "        for line in tqdm(inp):\n",
    "            d = json.loads(line)\n",
    "            if \"comments\" in d:\n",
    "                for c in d[\"comments\"]:\n",
    "                    data.append({\"url\": d[\"url\"], **c})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15384667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse relative dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    # date when crawled 11th June 2019\n",
    "    d = datetime.datetime(2019, 6, 11, 12, 0)\n",
    "    idx = x.find('—')\n",
    "    return dateparser.parse(x[idx:], languages=['de'], settings={'RELATIVE_BASE': d})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15384667/15384667 [3:10:19<00:00, 1347.22it/s]\n"
     ]
    }
   ],
   "source": [
    "parsed = Parallel(n_jobs=4)(delayed(parse)(i) for i in tqdm(df['date'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('parsed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('parsed_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by='date', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15384667, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['text', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2145505</th>\n",
       "      <td>2019-06-11 11:59:50</td>\n",
       "      <td>\"Does a form of capitalism that generates incr...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-05/kapital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176690</th>\n",
       "      <td>2019-06-11 11:59:49</td>\n",
       "      <td>Seehofer hat wiedermal einen Seehofer-Witz gem...</td>\n",
       "      <td>https://www.zeit.de/politik/deutschland/2019-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368511</th>\n",
       "      <td>2019-06-11 11:59:48</td>\n",
       "      <td>\"In Deutschland wandern rund vier Tonnen Leben...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-06/muellve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6368951</th>\n",
       "      <td>2019-06-11 11:59:44</td>\n",
       "      <td>Vom Niveau nur knapp über dem Champions League...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/uefa-nations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010560</th>\n",
       "      <td>2019-06-11 11:59:32</td>\n",
       "      <td>Mooomennt da kommt mir eine Idee...\\nBäume mac...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-06/klimasc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488465</th>\n",
       "      <td>2019-06-11 11:59:28</td>\n",
       "      <td>Verständlich, dass sich Medien nach fast 20 Ja...</td>\n",
       "      <td>https://www.zeit.de/politik/deutschland/2019-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368365</th>\n",
       "      <td>2019-06-11 11:59:11</td>\n",
       "      <td>So schlimm ist es nicht.\\nAber leider orientie...</td>\n",
       "      <td>https://www.zeit.de/politik/deutschland/2019-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765230</th>\n",
       "      <td>2019-06-11 11:59:07</td>\n",
       "      <td>Dieses Täuschungsmanöver..\\nwäre bei keinem Ha...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/sc-paderborn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367797</th>\n",
       "      <td>2019-06-11 11:59:05</td>\n",
       "      <td>Der Kommentar, auf den Sie Bezug nehmen, wurde...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/deutsche-fus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368643</th>\n",
       "      <td>2019-06-11 11:59:02</td>\n",
       "      <td>Mein Wattebausch kann sogar etwas aufnehmen un...</td>\n",
       "      <td>https://www.zeit.de/politik/ausland/2019-06/ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367798</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>Ha, das beweist, dass Löw überflüssig ist.</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/deutsche-fus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368611</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>Kühnert wird mit seinen Debatten aber nix bewe...</td>\n",
       "      <td>https://www.zeit.de/politik/deutschland/2019-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709924</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>Streng genommen ist es gar keine Steuer, sonde...</td>\n",
       "      <td>https://www.zeit.de/2019/24/klimapolitik-co2-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010174</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>Guter kurzer Beitrag, aber das Clickbaiting lo...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-06/klimasc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862563</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>\"johnson scheint noch immer auf drogen zu sein...</td>\n",
       "      <td>https://www.zeit.de/politik/ausland/2019-06/br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145687</th>\n",
       "      <td>2019-06-11 11:59:00</td>\n",
       "      <td>\"Does a form of capitalism that generates incr...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-05/kapital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5456641</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Warum nicht einen präparierten Privatjet nach ...</td>\n",
       "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368246</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Wohin der Wandel passiert, bleibt noch offen.\\...</td>\n",
       "      <td>https://www.zeit.de/politik/deutschland/2019-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886218</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Leroy Sané und Thilo Kehrer. Wobei Kehrer ja g...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/fussball-bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368633</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Wenn die Klausuren tatsächlich zu schwer waren...</td>\n",
       "      <td>https://www.zeit.de/hamburg/2019-06/schulbehoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709929</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Na..dann erweitert sich das Parteienspektrum D...</td>\n",
       "      <td>https://www.zeit.de/2019/24/klimapolitik-co2-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709928</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Da der Autoverkehr auch einen großen Anteil am...</td>\n",
       "      <td>https://www.zeit.de/2019/24/klimapolitik-co2-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485924</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Seit 1998 gab es eine rot-grüne Regierungskoal...</td>\n",
       "      <td>https://www.zeit.de/mobilitaet/2019-06/klimasc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367796</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Entfernt. Bitte bleiben Sie beim Thema. Danke,...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/deutsche-fus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162028</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Tatsächlich scheint mir Milgrams Experiment au...</td>\n",
       "      <td>https://www.zeit.de/zeit-wissen/2019/03/psycho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368617</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Er wird ihr gesagt haben, dass sie nach Herrn ...</td>\n",
       "      <td>https://www.zeit.de/politik/ausland/2019-06/ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145969</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>Ist dieser Engländer ein Brexit-Anhänger? Der ...</td>\n",
       "      <td>https://www.zeit.de/wirtschaft/2019-04/kapital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988249</th>\n",
       "      <td>2019-06-11 11:58:00</td>\n",
       "      <td>\"Einsatzkräfte stoppen 1.000 Migranten auf dem...</td>\n",
       "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5367795</th>\n",
       "      <td>2019-06-11 11:57:00</td>\n",
       "      <td>Entfernt. Bitte bleiben Sie beim Thema. Danke,...</td>\n",
       "      <td>https://www.zeit.de/sport/2019-06/deutsche-fus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709926</th>\n",
       "      <td>2019-06-11 11:57:00</td>\n",
       "      <td>Können Sie sich an Trittin und seine Aussage, ...</td>\n",
       "      <td>https://www.zeit.de/2019/24/klimapolitik-co2-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950313</th>\n",
       "      <td>2005-10-15 00:15:00</td>\n",
       "      <td>DefinitionGrundsätzlich hat unserer russischer...</td>\n",
       "      <td>https://www.zeit.de/online/2005/42/kaukasus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950312</th>\n",
       "      <td>2005-10-14 07:03:00</td>\n",
       "      <td>Wann?Für mich Russen ist es äußerst  grauenhaf...</td>\n",
       "      <td>https://www.zeit.de/online/2005/42/kaukasus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036012</th>\n",
       "      <td>2005-10-12 13:18:00</td>\n",
       "      <td>Interessante RechercheIch freue mich, dass ich...</td>\n",
       "      <td>https://www.zeit.de/2005/41/B-Arabien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796661</th>\n",
       "      <td>2005-10-10 18:14:00</td>\n",
       "      <td>Ökologisch bedenklichEiner Autobahnmaut stimme...</td>\n",
       "      <td>https://www.zeit.de/online/2005/41/pkw_maut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796660</th>\n",
       "      <td>2005-10-10 15:03:00</td>\n",
       "      <td>ungerechtDas naheliegendste Regulativ für Viel...</td>\n",
       "      <td>https://www.zeit.de/online/2005/41/pkw_maut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796659</th>\n",
       "      <td>2005-10-10 14:43:00</td>\n",
       "      <td>Hilfe, die Pkw Maut kommtSchäuble, Inneminster...</td>\n",
       "      <td>https://www.zeit.de/online/2005/41/pkw_maut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796658</th>\n",
       "      <td>2005-10-08 21:06:00</td>\n",
       "      <td>PlanlosigkeitEs ist schon faszinierend.\\nDa wi...</td>\n",
       "      <td>https://www.zeit.de/online/2005/41/pkw_maut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649568</th>\n",
       "      <td>2005-09-27 14:54:00</td>\n",
       "      <td>Die \"deutsche industrielle Loesung\"Wie hatte s...</td>\n",
       "      <td>https://www.zeit.de/online/2005/39/porsche-vw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649567</th>\n",
       "      <td>2005-09-27 14:31:00</td>\n",
       "      <td>VW ist besser als ihr denktAlso wenn das schla...</td>\n",
       "      <td>https://www.zeit.de/online/2005/39/porsche-vw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649566</th>\n",
       "      <td>2005-09-27 10:48:00</td>\n",
       "      <td>interessantes ExperimentEin Unternehmen kauft ...</td>\n",
       "      <td>https://www.zeit.de/online/2005/39/porsche-vw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332716</th>\n",
       "      <td>2005-09-22 15:35:00</td>\n",
       "      <td>Abraham die nächsteConny, was war unseriös dra...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332715</th>\n",
       "      <td>2005-09-22 15:03:00</td>\n",
       "      <td>noch mal AbrahamSorry, der link ging voll dane...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332714</th>\n",
       "      <td>2005-09-22 12:13:00</td>\n",
       "      <td>Institut for Historical ReviewEine kleine Anme...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332713</th>\n",
       "      <td>2005-09-22 06:13:00</td>\n",
       "      <td>zu Conny Austs KommentarGuter Link. Inzwischen...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332731</th>\n",
       "      <td>2005-09-22 02:40:00</td>\n",
       "      <td>David AbrahamNur eine kleine Anmerkung zum Wei...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332730</th>\n",
       "      <td>2005-09-21 19:18:00</td>\n",
       "      <td>nicht WeimarJa, die Vergleiche mit Weimar lieg...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332729</th>\n",
       "      <td>2005-09-21 16:55:00</td>\n",
       "      <td>EindimensionalEs standen nicht nur ein Finanz-...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332728</th>\n",
       "      <td>2005-09-21 16:25:00</td>\n",
       "      <td>genug, already...ach du gruene neune, bitte ni...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332559</th>\n",
       "      <td>2005-09-21 14:20:00</td>\n",
       "      <td>ExpertenNoch ein US-Kommentar zur Deutschland-...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333008</th>\n",
       "      <td>2005-09-21 14:13:00</td>\n",
       "      <td>Schon wieder WeimarLiebe DeutschInnen und Deut...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332557</th>\n",
       "      <td>2005-09-21 11:19:00</td>\n",
       "      <td>Die Fernseh-HysterokratieWenn ein gewisser Ger...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333010</th>\n",
       "      <td>2005-09-21 10:18:00</td>\n",
       "      <td>\\NIch halte den Vergleich zwischen der Weimare...</td>\n",
       "      <td>https://www.zeit.de/online/2005/38/wahl_abraha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792186</th>\n",
       "      <td>2005-08-29 14:33:00</td>\n",
       "      <td>Endlich!Endlich kann man nur rufen! Auch wenn ...</td>\n",
       "      <td>https://www.zeit.de/online/2005/35/armstrong/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791993</th>\n",
       "      <td>2005-08-29 09:26:00</td>\n",
       "      <td>HexenkücheNun gereicht die Art und Weise, wie ...</td>\n",
       "      <td>https://www.zeit.de/online/2005/35/armstrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792184</th>\n",
       "      <td>2005-08-29 08:46:00</td>\n",
       "      <td>HexerIch hoffe nicht der Übersetzung zum Opfer...</td>\n",
       "      <td>https://www.zeit.de/online/2005/35/armstrong/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131383</th>\n",
       "      <td>2005-08-22 14:25:00</td>\n",
       "      <td>Kompetenzteam ohne KompetenzenEs ist erstaunli...</td>\n",
       "      <td>https://www.zeit.de/online/2005/33/union_div?p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131391</th>\n",
       "      <td>2005-08-17 13:50:00</td>\n",
       "      <td>nichts halbes und nichts ganzesDas hab ich mir...</td>\n",
       "      <td>https://www.zeit.de/online/2005/33/union_div/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131386</th>\n",
       "      <td>2005-08-17 12:47:00</td>\n",
       "      <td>KirchhofDie Nominierung Kirchhofs zeigt nicht ...</td>\n",
       "      <td>https://www.zeit.de/online/2005/33/union_div/k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131385</th>\n",
       "      <td>2005-08-17 09:29:00</td>\n",
       "      <td>SeltsamkeitenFast Unbemerkt ist es der CDU gel...</td>\n",
       "      <td>https://www.zeit.de/online/2005/33/union_div/k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131497</th>\n",
       "      <td>2005-08-16 10:48:00</td>\n",
       "      <td>Umdenken in der Besetzung von ParteipostenMit ...</td>\n",
       "      <td>https://www.zeit.de/online/2005/33/union_div?p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12190782 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "2145505 2019-06-11 11:59:50   \n",
       "5176690 2019-06-11 11:59:49   \n",
       "2368511 2019-06-11 11:59:48   \n",
       "6368951 2019-06-11 11:59:44   \n",
       "2010560 2019-06-11 11:59:32   \n",
       "1488465 2019-06-11 11:59:28   \n",
       "2368365 2019-06-11 11:59:11   \n",
       "5765230 2019-06-11 11:59:07   \n",
       "5367797 2019-06-11 11:59:05   \n",
       "2368643 2019-06-11 11:59:02   \n",
       "5367798 2019-06-11 11:59:00   \n",
       "2368611 2019-06-11 11:59:00   \n",
       "5709924 2019-06-11 11:59:00   \n",
       "2010174 2019-06-11 11:59:00   \n",
       "5862563 2019-06-11 11:59:00   \n",
       "2145687 2019-06-11 11:59:00   \n",
       "5456641 2019-06-11 11:58:00   \n",
       "2368246 2019-06-11 11:58:00   \n",
       "5886218 2019-06-11 11:58:00   \n",
       "2368633 2019-06-11 11:58:00   \n",
       "5709929 2019-06-11 11:58:00   \n",
       "5709928 2019-06-11 11:58:00   \n",
       "1485924 2019-06-11 11:58:00   \n",
       "5367796 2019-06-11 11:58:00   \n",
       "6162028 2019-06-11 11:58:00   \n",
       "2368617 2019-06-11 11:58:00   \n",
       "2145969 2019-06-11 11:58:00   \n",
       "3988249 2019-06-11 11:58:00   \n",
       "5367795 2019-06-11 11:57:00   \n",
       "5709926 2019-06-11 11:57:00   \n",
       "...                     ...   \n",
       "4950313 2005-10-15 00:15:00   \n",
       "4950312 2005-10-14 07:03:00   \n",
       "6036012 2005-10-12 13:18:00   \n",
       "1796661 2005-10-10 18:14:00   \n",
       "1796660 2005-10-10 15:03:00   \n",
       "1796659 2005-10-10 14:43:00   \n",
       "1796658 2005-10-08 21:06:00   \n",
       "649568  2005-09-27 14:54:00   \n",
       "649567  2005-09-27 14:31:00   \n",
       "649566  2005-09-27 10:48:00   \n",
       "2332716 2005-09-22 15:35:00   \n",
       "2332715 2005-09-22 15:03:00   \n",
       "2332714 2005-09-22 12:13:00   \n",
       "2332713 2005-09-22 06:13:00   \n",
       "2332731 2005-09-22 02:40:00   \n",
       "2332730 2005-09-21 19:18:00   \n",
       "2332729 2005-09-21 16:55:00   \n",
       "2332728 2005-09-21 16:25:00   \n",
       "2332559 2005-09-21 14:20:00   \n",
       "2333008 2005-09-21 14:13:00   \n",
       "2332557 2005-09-21 11:19:00   \n",
       "2333010 2005-09-21 10:18:00   \n",
       "2792186 2005-08-29 14:33:00   \n",
       "2791993 2005-08-29 09:26:00   \n",
       "2792184 2005-08-29 08:46:00   \n",
       "5131383 2005-08-22 14:25:00   \n",
       "5131391 2005-08-17 13:50:00   \n",
       "5131386 2005-08-17 12:47:00   \n",
       "5131385 2005-08-17 09:29:00   \n",
       "5131497 2005-08-16 10:48:00   \n",
       "\n",
       "                                                      text  \\\n",
       "2145505  \"Does a form of capitalism that generates incr...   \n",
       "5176690  Seehofer hat wiedermal einen Seehofer-Witz gem...   \n",
       "2368511  \"In Deutschland wandern rund vier Tonnen Leben...   \n",
       "6368951  Vom Niveau nur knapp über dem Champions League...   \n",
       "2010560  Mooomennt da kommt mir eine Idee...\\nBäume mac...   \n",
       "1488465  Verständlich, dass sich Medien nach fast 20 Ja...   \n",
       "2368365  So schlimm ist es nicht.\\nAber leider orientie...   \n",
       "5765230  Dieses Täuschungsmanöver..\\nwäre bei keinem Ha...   \n",
       "5367797  Der Kommentar, auf den Sie Bezug nehmen, wurde...   \n",
       "2368643  Mein Wattebausch kann sogar etwas aufnehmen un...   \n",
       "5367798         Ha, das beweist, dass Löw überflüssig ist.   \n",
       "2368611  Kühnert wird mit seinen Debatten aber nix bewe...   \n",
       "5709924  Streng genommen ist es gar keine Steuer, sonde...   \n",
       "2010174  Guter kurzer Beitrag, aber das Clickbaiting lo...   \n",
       "5862563  \"johnson scheint noch immer auf drogen zu sein...   \n",
       "2145687  \"Does a form of capitalism that generates incr...   \n",
       "5456641  Warum nicht einen präparierten Privatjet nach ...   \n",
       "2368246  Wohin der Wandel passiert, bleibt noch offen.\\...   \n",
       "5886218  Leroy Sané und Thilo Kehrer. Wobei Kehrer ja g...   \n",
       "2368633  Wenn die Klausuren tatsächlich zu schwer waren...   \n",
       "5709929  Na..dann erweitert sich das Parteienspektrum D...   \n",
       "5709928  Da der Autoverkehr auch einen großen Anteil am...   \n",
       "1485924  Seit 1998 gab es eine rot-grüne Regierungskoal...   \n",
       "5367796  Entfernt. Bitte bleiben Sie beim Thema. Danke,...   \n",
       "6162028  Tatsächlich scheint mir Milgrams Experiment au...   \n",
       "2368617  Er wird ihr gesagt haben, dass sie nach Herrn ...   \n",
       "2145969  Ist dieser Engländer ein Brexit-Anhänger? Der ...   \n",
       "3988249  \"Einsatzkräfte stoppen 1.000 Migranten auf dem...   \n",
       "5367795  Entfernt. Bitte bleiben Sie beim Thema. Danke,...   \n",
       "5709926  Können Sie sich an Trittin und seine Aussage, ...   \n",
       "...                                                    ...   \n",
       "4950313  DefinitionGrundsätzlich hat unserer russischer...   \n",
       "4950312  Wann?Für mich Russen ist es äußerst  grauenhaf...   \n",
       "6036012  Interessante RechercheIch freue mich, dass ich...   \n",
       "1796661  Ökologisch bedenklichEiner Autobahnmaut stimme...   \n",
       "1796660  ungerechtDas naheliegendste Regulativ für Viel...   \n",
       "1796659  Hilfe, die Pkw Maut kommtSchäuble, Inneminster...   \n",
       "1796658  PlanlosigkeitEs ist schon faszinierend.\\nDa wi...   \n",
       "649568   Die \"deutsche industrielle Loesung\"Wie hatte s...   \n",
       "649567   VW ist besser als ihr denktAlso wenn das schla...   \n",
       "649566   interessantes ExperimentEin Unternehmen kauft ...   \n",
       "2332716  Abraham die nächsteConny, was war unseriös dra...   \n",
       "2332715  noch mal AbrahamSorry, der link ging voll dane...   \n",
       "2332714  Institut for Historical ReviewEine kleine Anme...   \n",
       "2332713  zu Conny Austs KommentarGuter Link. Inzwischen...   \n",
       "2332731  David AbrahamNur eine kleine Anmerkung zum Wei...   \n",
       "2332730  nicht WeimarJa, die Vergleiche mit Weimar lieg...   \n",
       "2332729  EindimensionalEs standen nicht nur ein Finanz-...   \n",
       "2332728  genug, already...ach du gruene neune, bitte ni...   \n",
       "2332559  ExpertenNoch ein US-Kommentar zur Deutschland-...   \n",
       "2333008  Schon wieder WeimarLiebe DeutschInnen und Deut...   \n",
       "2332557  Die Fernseh-HysterokratieWenn ein gewisser Ger...   \n",
       "2333010  \\NIch halte den Vergleich zwischen der Weimare...   \n",
       "2792186  Endlich!Endlich kann man nur rufen! Auch wenn ...   \n",
       "2791993  HexenkücheNun gereicht die Art und Weise, wie ...   \n",
       "2792184  HexerIch hoffe nicht der Übersetzung zum Opfer...   \n",
       "5131383  Kompetenzteam ohne KompetenzenEs ist erstaunli...   \n",
       "5131391  nichts halbes und nichts ganzesDas hab ich mir...   \n",
       "5131386  KirchhofDie Nominierung Kirchhofs zeigt nicht ...   \n",
       "5131385  SeltsamkeitenFast Unbemerkt ist es der CDU gel...   \n",
       "5131497  Umdenken in der Besetzung von ParteipostenMit ...   \n",
       "\n",
       "                                                       url  \n",
       "2145505  https://www.zeit.de/wirtschaft/2019-05/kapital...  \n",
       "5176690  https://www.zeit.de/politik/deutschland/2019-0...  \n",
       "2368511  https://www.zeit.de/wirtschaft/2019-06/muellve...  \n",
       "6368951  https://www.zeit.de/sport/2019-06/uefa-nations...  \n",
       "2010560  https://www.zeit.de/wirtschaft/2019-06/klimasc...  \n",
       "1488465  https://www.zeit.de/politik/deutschland/2019-0...  \n",
       "2368365  https://www.zeit.de/politik/deutschland/2019-0...  \n",
       "5765230  https://www.zeit.de/sport/2019-06/sc-paderborn...  \n",
       "5367797  https://www.zeit.de/sport/2019-06/deutsche-fus...  \n",
       "2368643  https://www.zeit.de/politik/ausland/2019-06/ge...  \n",
       "5367798  https://www.zeit.de/sport/2019-06/deutsche-fus...  \n",
       "2368611  https://www.zeit.de/politik/deutschland/2019-0...  \n",
       "5709924  https://www.zeit.de/2019/24/klimapolitik-co2-s...  \n",
       "2010174  https://www.zeit.de/wirtschaft/2019-06/klimasc...  \n",
       "5862563  https://www.zeit.de/politik/ausland/2019-06/br...  \n",
       "2145687  https://www.zeit.de/wirtschaft/2019-05/kapital...  \n",
       "5456641  https://www.zeit.de/gesellschaft/zeitgeschehen...  \n",
       "2368246  https://www.zeit.de/politik/deutschland/2019-0...  \n",
       "5886218  https://www.zeit.de/sport/2019-06/fussball-bel...  \n",
       "2368633  https://www.zeit.de/hamburg/2019-06/schulbehoe...  \n",
       "5709929  https://www.zeit.de/2019/24/klimapolitik-co2-s...  \n",
       "5709928  https://www.zeit.de/2019/24/klimapolitik-co2-s...  \n",
       "1485924  https://www.zeit.de/mobilitaet/2019-06/klimasc...  \n",
       "5367796  https://www.zeit.de/sport/2019-06/deutsche-fus...  \n",
       "6162028  https://www.zeit.de/zeit-wissen/2019/03/psycho...  \n",
       "2368617  https://www.zeit.de/politik/ausland/2019-06/ge...  \n",
       "2145969  https://www.zeit.de/wirtschaft/2019-04/kapital...  \n",
       "3988249  https://www.zeit.de/gesellschaft/zeitgeschehen...  \n",
       "5367795  https://www.zeit.de/sport/2019-06/deutsche-fus...  \n",
       "5709926  https://www.zeit.de/2019/24/klimapolitik-co2-s...  \n",
       "...                                                    ...  \n",
       "4950313        https://www.zeit.de/online/2005/42/kaukasus  \n",
       "4950312        https://www.zeit.de/online/2005/42/kaukasus  \n",
       "6036012              https://www.zeit.de/2005/41/B-Arabien  \n",
       "1796661        https://www.zeit.de/online/2005/41/pkw_maut  \n",
       "1796660        https://www.zeit.de/online/2005/41/pkw_maut  \n",
       "1796659        https://www.zeit.de/online/2005/41/pkw_maut  \n",
       "1796658        https://www.zeit.de/online/2005/41/pkw_maut  \n",
       "649568       https://www.zeit.de/online/2005/39/porsche-vw  \n",
       "649567       https://www.zeit.de/online/2005/39/porsche-vw  \n",
       "649566       https://www.zeit.de/online/2005/39/porsche-vw  \n",
       "2332716  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332715  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332714  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332713  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332731  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332730  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332729  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332728  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332559    https://www.zeit.de/online/2005/38/wahl_abraham  \n",
       "2333008  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2332557    https://www.zeit.de/online/2005/38/wahl_abraham  \n",
       "2333010  https://www.zeit.de/online/2005/38/wahl_abraha...  \n",
       "2792186  https://www.zeit.de/online/2005/35/armstrong/s...  \n",
       "2791993       https://www.zeit.de/online/2005/35/armstrong  \n",
       "2792184  https://www.zeit.de/online/2005/35/armstrong/s...  \n",
       "5131383  https://www.zeit.de/online/2005/33/union_div?p...  \n",
       "5131391  https://www.zeit.de/online/2005/33/union_div/s...  \n",
       "5131386  https://www.zeit.de/online/2005/33/union_div/k...  \n",
       "5131385  https://www.zeit.de/online/2005/33/union_div/k...  \n",
       "5131497  https://www.zeit.de/online/2005/33/union_div?p...  \n",
       "\n",
       "[12190782 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.qcut(df['date'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2145505           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5176690           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368511           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "6368951           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2010560           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "1488465           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368365           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5765230           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5367797           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368643           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5367798           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368611           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5709924           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2010174           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5862563           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2145687           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5456641           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368246           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5886218           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368633           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5709929           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5709928           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "1485924           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5367796           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "6162028           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2368617           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "2145969           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "3988249           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5367795           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "5709926           (2019-01-11 12:00:00, 2019-06-11 11:59:50]\n",
       "                                 ...                        \n",
       "4950313    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "4950312    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "6036012    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "1796661    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "1796660    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "1796659    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "1796658    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "649568     (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "649567     (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "649566     (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332716    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332715    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332714    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332713    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332731    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332730    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332729    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332728    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332559    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2333008    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2332557    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2333010    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2792186    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2791993    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "2792184    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "5131383    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "5131391    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "5131386    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "5131385    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "5131497    (2005-08-16 10:47:59.999999999, 2012-12-10 13:...\n",
       "Name: date, Length: 12190782, dtype: category\n",
       "Categories (10, interval[datetime64[ns]]): [(2005-08-16 10:47:59.999999999, 2012-12-10 13:... < (2012-12-10 13:26:00, 2014-12-10 17:16:00] < (2014-12-10 17:16:00, 2016-01-26 12:46:18] < (2016-01-26 12:46:18, 2016-10-19 12:18:00] ... (2017-11-30 08:58:00, 2018-04-01 19:52:00] < (2018-04-01 19:52:00, 2018-08-11 12:00:00] < (2018-08-11 12:00:00, 2019-01-11 12:00:00] < (2019-01-11 12:00:00, 2019-06-11 11:59:50]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    3257309\n",
       "2017    2367352\n",
       "2016    1680063\n",
       "2019    1333176\n",
       "2015    1064534\n",
       "2014     751005\n",
       "2013     494623\n",
       "2012     481302\n",
       "2011     427243\n",
       "2010     226579\n",
       "2009      79962\n",
       "2008      22065\n",
       "2006       3493\n",
       "2007       1974\n",
       "2005        102\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['group'] = df['year'].apply(lambda x: x if x > 2010 else 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    3257309\n",
       "2017    2367352\n",
       "2016    1680063\n",
       "2019    1333176\n",
       "2015    1064534\n",
       "2014     751005\n",
       "2013     494623\n",
       "2012     481302\n",
       "2011     427243\n",
       "2010     334175\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean, split into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sents(texts):\n",
    "    tokenizer = Tokenizer(split_camel_case=True, token_classes=False, extra_info=False)\n",
    "    sentence_splitter = SentenceSplitter(is_tuple=False)\n",
    "    \n",
    "    results = []\n",
    "    for text in texts:\n",
    "        text = clean(text, lang='de', lower=False)\n",
    "        tokens = tokenizer.tokenize_paragraph(text)\n",
    "        sentences = sentence_splitter.split(tokens)\n",
    "        cleaned = [' '.join(s) for s in sentences]\n",
    "        results.append(cleaned)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(li):\n",
    "    for l in li:\n",
    "        for x in l:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Parallel(n_jobs=4)(delayed(get_sents)(row) for row in tqdm(list(chunks(df['text'], 10000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( results, open( \"/mnt/data2/results_sentes.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open( \"/mnt/data2/results_sentes.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sents'] = list(combine(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in tqdm(df[['group', 'sents']].iterrows(), total=df.shape[0]):\n",
    "    for s in row['sents']:\n",
    "        sents_data.append({'text': s, 'group': row['group']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51973684"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents = pd.DataFrame(sents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>\" Does a form of capitalism that generates inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>At present , democracy seems unable to find an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>\" Also das ist wirklich eine gute Zusammenfass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Fraglich ist , ob dieser Punkt schon erreicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>Seehofer hat wiedermal einen Seehofer-Witz gem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>\" In Deutschland wandern rund vier Tonnen Lebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>\" Na ja , wenn es nur 4 Tonnen sind , wo liegt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>Vom Niveau nur knapp über dem Champions League...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019</td>\n",
       "      <td>Ist wohl die Strafe für eine absolut überragen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>Mooomennt da kommt mir eine Idee ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019</td>\n",
       "      <td>Bäume machen aus CO2 Sauerstoff ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>Als Waldbesitzer dürfte man dann doch das Äqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>Verständlich , dass sich Medien nach fast 20 J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>Vielleicht werde ich älter .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>Mir liegt die Sache an sich immer noch , mehr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>So schlimm ist es nicht .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>Aber leider orientiert sich Arbeitnehmerpoliti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>Bei einem großen Arbeitgeber mit Tarifbindung ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>Das kann man auch an den verbliebenen SPD Hoch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>Wo schaffte es die SPD selbst bei der letzten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019</td>\n",
       "      <td>Jo .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019</td>\n",
       "      <td>In Wolfsburg .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019</td>\n",
       "      <td>Zum Beispiel .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019</td>\n",
       "      <td>Dieses Täuschungsmanöver .. wäre bei keinem Ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019</td>\n",
       "      <td>Beim DFB aber doch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019</td>\n",
       "      <td>Der Kommentar , auf den Sie Bezug nehmen , wur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019</td>\n",
       "      <td>Mein Wattebausch kann sogar etwas aufnehmen un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019</td>\n",
       "      <td>Damit ist er dem Potus weit überlegen .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019</td>\n",
       "      <td>Naja .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019</td>\n",
       "      <td>Das mit dem twittern übt er noch .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973654</th>\n",
       "      <td>2010</td>\n",
       "      <td>Armstrong , ob mit oder ohne verunreinigtem Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973655</th>\n",
       "      <td>2010</td>\n",
       "      <td>Es muss ein wahrhafter Hexentrunk gewesen sein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973656</th>\n",
       "      <td>2010</td>\n",
       "      <td>Hexer Ich hoffe nicht der Übersetzung zum Opfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973657</th>\n",
       "      <td>2010</td>\n",
       "      <td>Ferner muss klar sein dass die enge Freundscha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973658</th>\n",
       "      <td>2010</td>\n",
       "      <td>Kompetenzteam ohne Kompetenzen Es ist erstaunl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973659</th>\n",
       "      <td>2010</td>\n",
       "      <td>Das heißt seine Kompetenz besteht darin die ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973660</th>\n",
       "      <td>2010</td>\n",
       "      <td>Ist das die neue Ehrlichkeit ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973661</th>\n",
       "      <td>2010</td>\n",
       "      <td>Was heißt das für einen Regierungswechsel : he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973662</th>\n",
       "      <td>2010</td>\n",
       "      <td>Was mir im \" Kompetenzteam \" fehlt ist ein kla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973663</th>\n",
       "      <td>2010</td>\n",
       "      <td>nichts halbes und nichts ganzes Das hab ich mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973664</th>\n",
       "      <td>2010</td>\n",
       "      <td>P. S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973665</th>\n",
       "      <td>2010</td>\n",
       "      <td>Kirchhof Die Nominierung Kirchhofs zeigt nicht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973666</th>\n",
       "      <td>2010</td>\n",
       "      <td>Kirchhof ist einer der namhaftesten Gegner ihr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973667</th>\n",
       "      <td>2010</td>\n",
       "      <td>Merkel wird sich nun die Frage gefallen lassen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973668</th>\n",
       "      <td>2010</td>\n",
       "      <td>Ein Experte von ausserhalb der Politik mag ein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973669</th>\n",
       "      <td>2010</td>\n",
       "      <td>Ein Minister soll nicht in erster Linie selber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973670</th>\n",
       "      <td>2010</td>\n",
       "      <td>Seltsamkeiten Fast Unbemerkt ist es der CDU ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973671</th>\n",
       "      <td>2010</td>\n",
       "      <td>Vor allem die Nominierung des saarländischen M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973672</th>\n",
       "      <td>2010</td>\n",
       "      <td>Wie schon des öfteren von ihm zu hören war , w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973673</th>\n",
       "      <td>2010</td>\n",
       "      <td>Das , was er schon in einem Bundesland nicht l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973674</th>\n",
       "      <td>2010</td>\n",
       "      <td>Einer Sache kann man sich sicher sein : in Pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973675</th>\n",
       "      <td>2010</td>\n",
       "      <td>Umdenken in der Besetzung von Parteiposten Mit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973676</th>\n",
       "      <td>2010</td>\n",
       "      <td>Dies wäre - vorausgesetzt die CDU gewinnt die ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973677</th>\n",
       "      <td>2010</td>\n",
       "      <td>Zu fragen bleibt jedoch , ob Kirchhof auch mit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973678</th>\n",
       "      <td>2010</td>\n",
       "      <td>Im Prinzip ist das Steuerkonzept von Kirchhof ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973679</th>\n",
       "      <td>2010</td>\n",
       "      <td>Fraglich ist nur , ob dies auch solche Leute ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973680</th>\n",
       "      <td>2010</td>\n",
       "      <td>Diese äußern immer wieder in der Öffentlichkei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973681</th>\n",
       "      <td>2010</td>\n",
       "      <td>Dass in der Realität kein einziger Millionär t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973682</th>\n",
       "      <td>2010</td>\n",
       "      <td>Wahrscheinlich deswegen , weil die betreffende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51973683</th>\n",
       "      <td>2010</td>\n",
       "      <td>Es bleibt zu hoffen , dass Prof. Kirchhof tats...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51973684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          group                                               text\n",
       "0          2019  \" Does a form of capitalism that generates inc...\n",
       "1          2019  At present , democracy seems unable to find an...\n",
       "2          2019  \" Also das ist wirklich eine gute Zusammenfass...\n",
       "3          2019  Fraglich ist , ob dieser Punkt schon erreicht ...\n",
       "4          2019  Seehofer hat wiedermal einen Seehofer-Witz gem...\n",
       "5          2019  \" In Deutschland wandern rund vier Tonnen Lebe...\n",
       "6          2019  \" Na ja , wenn es nur 4 Tonnen sind , wo liegt...\n",
       "7          2019  Vom Niveau nur knapp über dem Champions League...\n",
       "8          2019  Ist wohl die Strafe für eine absolut überragen...\n",
       "9          2019               Mooomennt da kommt mir eine Idee ...\n",
       "10         2019               Bäume machen aus CO2 Sauerstoff ....\n",
       "11         2019  Als Waldbesitzer dürfte man dann doch das Äqui...\n",
       "12         2019  Verständlich , dass sich Medien nach fast 20 J...\n",
       "13         2019                       Vielleicht werde ich älter .\n",
       "14         2019  Mir liegt die Sache an sich immer noch , mehr ...\n",
       "15         2019                          So schlimm ist es nicht .\n",
       "16         2019  Aber leider orientiert sich Arbeitnehmerpoliti...\n",
       "17         2019  Bei einem großen Arbeitgeber mit Tarifbindung ...\n",
       "18         2019  Das kann man auch an den verbliebenen SPD Hoch...\n",
       "19         2019  Wo schaffte es die SPD selbst bei der letzten ...\n",
       "20         2019                                               Jo .\n",
       "21         2019                                     In Wolfsburg .\n",
       "22         2019                                     Zum Beispiel .\n",
       "23         2019  Dieses Täuschungsmanöver .. wäre bei keinem Ha...\n",
       "24         2019                             Beim DFB aber doch ...\n",
       "25         2019  Der Kommentar , auf den Sie Bezug nehmen , wur...\n",
       "26         2019  Mein Wattebausch kann sogar etwas aufnehmen un...\n",
       "27         2019            Damit ist er dem Potus weit überlegen .\n",
       "28         2019                                             Naja .\n",
       "29         2019                 Das mit dem twittern übt er noch .\n",
       "...         ...                                                ...\n",
       "51973654   2010  Armstrong , ob mit oder ohne verunreinigtem Pi...\n",
       "51973655   2010  Es muss ein wahrhafter Hexentrunk gewesen sein...\n",
       "51973656   2010  Hexer Ich hoffe nicht der Übersetzung zum Opfe...\n",
       "51973657   2010  Ferner muss klar sein dass die enge Freundscha...\n",
       "51973658   2010  Kompetenzteam ohne Kompetenzen Es ist erstaunl...\n",
       "51973659   2010  Das heißt seine Kompetenz besteht darin die ni...\n",
       "51973660   2010                     Ist das die neue Ehrlichkeit ?\n",
       "51973661   2010  Was heißt das für einen Regierungswechsel : he...\n",
       "51973662   2010  Was mir im \" Kompetenzteam \" fehlt ist ein kla...\n",
       "51973663   2010  nichts halbes und nichts ganzes Das hab ich mi...\n",
       "51973664   2010                                              P. S.\n",
       "51973665   2010  Kirchhof Die Nominierung Kirchhofs zeigt nicht...\n",
       "51973666   2010  Kirchhof ist einer der namhaftesten Gegner ihr...\n",
       "51973667   2010  Merkel wird sich nun die Frage gefallen lassen...\n",
       "51973668   2010  Ein Experte von ausserhalb der Politik mag ein...\n",
       "51973669   2010  Ein Minister soll nicht in erster Linie selber...\n",
       "51973670   2010  Seltsamkeiten Fast Unbemerkt ist es der CDU ge...\n",
       "51973671   2010  Vor allem die Nominierung des saarländischen M...\n",
       "51973672   2010  Wie schon des öfteren von ihm zu hören war , w...\n",
       "51973673   2010  Das , was er schon in einem Bundesland nicht l...\n",
       "51973674   2010  Einer Sache kann man sich sicher sein : in Pet...\n",
       "51973675   2010  Umdenken in der Besetzung von Parteiposten Mit...\n",
       "51973676   2010  Dies wäre - vorausgesetzt die CDU gewinnt die ...\n",
       "51973677   2010  Zu fragen bleibt jedoch , ob Kirchhof auch mit...\n",
       "51973678   2010  Im Prinzip ist das Steuerkonzept von Kirchhof ...\n",
       "51973679   2010  Fraglich ist nur , ob dies auch solche Leute ,...\n",
       "51973680   2010  Diese äußern immer wieder in der Öffentlichkei...\n",
       "51973681   2010  Dass in der Realität kein einziger Millionär t...\n",
       "51973682   2010  Wahrscheinlich deswegen , weil die betreffende...\n",
       "51973683   2010  Es bleibt zu hoffen , dass Prof. Kirchhof tats...\n",
       "\n",
       "[51973684 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_pickle('/mnt/data2/results_sents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents = pd.read_pickle('/mnt/data2/results_sents.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents = df_sents[df_sents['text'].str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50692789, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507/507 [4:07:32<00:00, 18.54s/it]\n"
     ]
    }
   ],
   "source": [
    "res = list(lemmatize(df_sents['text'].values, n_jobs=4, chunk_size=100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['text'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_pickle('/mnt/data2/results_sents_lemma.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cl(x):\n",
    "    return clean(x, fix_unicode=False, to_ascii=False, no_urls=True, no_digits=True, no_punct=True, no_line_breaks=True, lang='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Parallel(n_jobs=4)(delayed(cl)(row) for row in tqdm(df_sents['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50692789"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does a form of capitalism that generates increasing inequality buen depends on mass consumption hav any other way out of its dilemma thanen to encourage households to take on unsustainable levels of deben',\n",
       " 'at present democracy seems unable to find an answer to that questionen',\n",
       " 'also das sein wirklich eine gut zusammenfassung der seltsam lage in der wir uns befinden und wahrscheinlich das einzig korrektiv die einkommensverteilung können nicht unendlich ungleich werden weil dann kein konsum mehr möglich sein',\n",
       " 'fraglich sein ob dieser punkt schon erreichen sein und ich fürchten nicht denn das bedeuten die einkommensverteilung können noch weit ungleich werden',\n",
       " 'seehofer haben wiedermal einen seehoferwitz machen über den außer seehofer niemand lachen können',\n",
       " 'in deutschland wandern rund vier tonne lebensmittel laut bundesumweltamt jährlich direkt vom supermarktregal in die tonne',\n",
       " 'na ja wenn es nur 0 tonne sein wo liegen das problem',\n",
       " 'vom niveau nur knapp über dem champion league finale',\n",
       " 'sein wohl die strafe für eine absolut überragend cl playoff phase',\n",
       " 'mooomennt da kommen mir eine idee']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['text'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(\n",
    "    \"\"\"\n",
    "á a ab aber ach acht achte achten achter achtes ag alle allein allem allen\n",
    "aller allerdings alles allgemeinen als also am an andere anderen anderem andern\n",
    "anders auch auf aus ausser außer ausserdem außerdem\n",
    "bald bei beide beiden beim beispiel bekannt bereits besonders besser besten bin\n",
    "bis bisher bist\n",
    "da dabei dadurch dafür dagegen daher dahin dahinter damals damit danach daneben\n",
    "dank dann daran darauf daraus darf darfst darin darüber darum darunter das\n",
    "dasein daselbst dass daß dasselbe davon davor dazu dazwischen dein deine deinem\n",
    "deiner dem dementsprechend demgegenüber demgemäss demgemäß demselben demzufolge\n",
    "den denen denn denselben der deren derjenige derjenigen dermassen dermaßen\n",
    "derselbe derselben des deshalb desselben dessen deswegen dich die diejenige\n",
    "diejenigen dies diese dieselbe dieselben diesem diesen dieser dieses dir doch\n",
    "dort drei drin dritte dritten dritter drittes du durch durchaus dürfen dürft\n",
    "durfte durften\n",
    "eben ebenso ehrlich eigen eigene eigenen eigener eigenes ein einander eine\n",
    "einem einen einer eines einigeeinigen einiger einiges einmal einmaleins elf en\n",
    "ende endlich entweder er erst erste ersten erster erstes es etwa etwas euch\n",
    "früher fünf fünfte fünften fünfter fünftes für\n",
    "gab ganz ganze ganzen ganzer ganzes gar gedurft gegen gegenüber gehabt gehen\n",
    "geht gekannt gekonnt gemacht gemocht gemusst genug gerade gern gesagt geschweige\n",
    "gewesen gewollt geworden gibt ging gleich gott gross groß grosse große grossen\n",
    "großen grosser großer grosses großes gut gute guter gutes\n",
    "habe haben habt hast hat hatte hätte hatten hätten heisst heißt her heute hier\n",
    "hin hinter hoch\n",
    "ich ihm ihn ihnen ihr ihre ihrem ihren ihrer ihres im immer in indem\n",
    "infolgedessen ins irgend ist\n",
    "ja jahr jahre jahren je jede jedem jeden jeder jedermann jedermanns jedoch\n",
    "jemand jemandem jemanden jene jenem jenen jener jenes jetzt\n",
    "kam kann kannst kaum kein keine keinem keinen keiner kleine kleinen kleiner\n",
    "kleines kommen kommt können könnt konnte könnte konnten kurz\n",
    "lang lange leicht leider lieber los\n",
    "machen macht machte mag magst man manche manchem manchen mancher manches mehr\n",
    "mein meine meinem meinen meiner meines mensch menschen mich mir mit mittel\n",
    "mochte möchte mochten mögen möglich mögt morgen muss muß müssen musst müsst\n",
    "musste mussten\n",
    "na nach nachdem nahm natürlich neben nein neue neuen neun neunte neunten neunter\n",
    "neuntes nicht nichts nie niemand niemandem niemanden noch nun nur\n",
    "ob oben oder offen oft ohne\n",
    "recht rechte rechten rechter rechtes richtig rund\n",
    "sagt sagte sah satt schlecht schon sechs sechste sechsten sechster sechstes\n",
    "sehr sei seid seien sein seine seinem seinen seiner seines seit seitdem selbst\n",
    "selbst sich sie sieben siebente siebenten siebenter siebentes siebte siebten\n",
    "siebter siebtes sind so solang solche solchem solchen solcher solches soll\n",
    "sollen sollte sollten sondern sonst sowie später statt\n",
    "tag tage tagen tat teil tel trotzdem tun\n",
    "über überhaupt übrigens uhr um und uns unser unsere unserer unter\n",
    "vergangene vergangenen viel viele vielem vielen vielleicht vier vierte vierten\n",
    "vierter viertes vom von vor\n",
    "wahr während währenddem währenddessen wann war wäre waren wart warum was wegen\n",
    "weil weit weiter weitere weiteren weiteres welche welchem welchen welcher\n",
    "welches wem wen wenig wenige weniger weniges wenigstens wenn wer werde werden\n",
    "werdet wessen wie wieder will willst wir wird wirklich wirst wo wohl wollen\n",
    "wollt wollte wollten worden wurde würde wurden würden\n",
    "zehn zehnte zehnten zehnter zehntes zeit zu zuerst zugleich zum zunächst zur\n",
    "zurück zusammen zwanzig zwar zwei zweite zweiten zweiter zweites zwischen\n",
    "\"\"\".split()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    tokens = [t for t in tokens if not t in STOP_WORDS]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = Parallel(n_jobs=4)(delayed(remove_stopwords)(row) for row in tqdm(df_sents['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents['text'] = final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents.to_pickle('/mnt/data2/final_zo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           does form of capitalism that generates increas...\n",
       "1           at present democracy seems unable to find answ...\n",
       "2           zusammenfassung seltsam lage befinden wahrsche...\n",
       "3           fraglich punkt erreichen fürchten bedeuten ein...\n",
       "4             seehofer wiedermal seehoferwitz seehofer lachen\n",
       "5           deutschland wandern tonne lebensmittel laut bu...\n",
       "6                                      0 tonne liegen problem\n",
       "7                         niveau knapp champion league finale\n",
       "8                  strafe absolut überragend cl playoff phase\n",
       "9                                              mooomennt idee\n",
       "10                                        baum co0 sauerstoff\n",
       "11          waldbesitzer äquivalent steuer sparen frage co...\n",
       "12          verständlich medium fast 00 absolut uneitel pr...\n",
       "13                                                        alt\n",
       "14                        liegen sache ausführend person herz\n",
       "15                                                    schlimm\n",
       "16          orientieren arbeitnehmerpolitik spd klasse arb...\n",
       "17                arbeitgeber tarifbindung stark gewerkschaft\n",
       "18                            verblieben spd hochburg ablesen\n",
       "19          schaffen spd letzen krachend verlorenen btw un...\n",
       "21                                                  wolfsburg\n",
       "22                                                           \n",
       "23                täuschungsmanöver handelsgericht durchgehen\n",
       "24                                                        dfb\n",
       "25                            kommentar bezug nehmen entfernt\n",
       "26                       wattebausch sogar aufnehmen behalten\n",
       "27                                            potus überlegen\n",
       "29                                              twittern üben\n",
       "30                                                       0000\n",
       "31                                       stehen zukunft bevor\n",
       "                                  ...                        \n",
       "51973653    lesen schlammschlacht fliegenschiss elefantenh...\n",
       "51973654            armstrong verunreinigt pipi tour gewinnen\n",
       "51973655                         wahrhaft hexentrunk anhalten\n",
       "51973656    hexer hoffen übersetzung opfer fallen lassen v...\n",
       "51973657    ferner klar eng freundschaft g bush schluss zu...\n",
       "51973658    kompetenzteam kompetenz erstaunlich frau merke...\n",
       "51973659    heißen kompetenz bestehen ausgewogen wirtschaf...\n",
       "51973660                                      neu ehrlichkeit\n",
       "51973661                             heißen regierungswechsel\n",
       "51973662    kompetenzteam fehlen klar bezug umwelt brauche...\n",
       "51973663    halbesen denken leute sogenant kompetensteam s...\n",
       "51973665    kirchhof nominierung kirchhofs zeigen dünn mer...\n",
       "51973666    kirchhof namhaftesten gegner mehrwertsteuerpla...\n",
       "51973667               merkel frage fallen lassen kurs gelten\n",
       "51973668    experte ausserhalb politik besetzung berater m...\n",
       "51973669    minister linie selber referentenentwurf fertig...\n",
       "51973670    seltsamkeit fast unbemerkt cdu gelingen nomini...\n",
       "51973671    nominierung saarländisch ministerpräsident mül...\n",
       "51973672    hören nah zukunft sicherlich verbessernd lage ...\n",
       "51973673                       bundesland leisten bundesebene\n",
       "51973674    sache sicher peter müller bekommen minister ve...\n",
       "51973675    umdenken besetzung parteiposten entscheidung p...\n",
       "51973676    voraussetzen cdu gewinnen wahl mal person ausg...\n",
       "51973677    fragen bleiben kirchhof politisch tagesgeschäf...\n",
       "51973678    prinzip steuerkonzept kirchhof einzig möglichk...\n",
       "51973679    fraglich leute sog linke v gewerkschaftsfunkti...\n",
       "51973680    äußern öffentlichkeit kritik steuerkonzept beg...\n",
       "51973681    realität einzig millionär tatsächlich 00 steue...\n",
       "51973682    wahrscheinlich desweg betreffend sog gewerksch...\n",
       "51973683    bleiben hoffen prof kirchhof tatsächlich amt k...\n",
       "Name: text, Length: 50692789, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sents['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 (1932455, 2)\n",
      "2011 (2215604, 2)\n",
      "2012 (2380169, 2)\n",
      "2013 (2477431, 2)\n",
      "2014 (3747399, 2)\n",
      "2015 (4983872, 2)\n",
      "2016 (6632652, 2)\n",
      "2017 (8908685, 2)\n",
      "2018 (11698714, 2)\n",
      "2019 (5715808, 2)\n"
     ]
    }
   ],
   "source": [
    "for year, group in df_sents.groupby('group'):\n",
    "    print(year, group.shape)\n",
    "    Path(f'/mnt/data2/ptf/groups/zo_{year}.txt').write_text('\\n'.join(group['text'].values) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sents = pd.read_pickle('/mnt/data2/final_zo.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
